# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
The provided bankmarketing dataset is an open source csv file which has to be analysed by a Scikit-learn Hyperdrive Pipeline and an AutoML approach to predict weather a client subscribes a term deposit or not.
![overview](https://github.com/Daniel-car1/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/docs/overview.PNG)
**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best perorming model was the VotingEnsemble, an AutomatedML approach which gave an accuracy of 0.916. [saved VotingEnsemble model](https://github.com/Daniel-car1/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/AutoMLb55d7c87225.zip)
| Run type        | Algorithm           | Accuracy  | Duration |
| ------------- |:-------------:| -----:| ----------:|
| Hyperdrive      | LinearRegression (SKlearn) | 0.914 | 54s |
| AutomatedML      | VotingEnsemble      |   0.916 | 1m25s |



## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The Scikit-learn Pipeline followes the CRIP-DM stages and tasks like importing data to obtain a editable dataset, cleaning and filtering data, tuning the Hyperparameters regularization strength and maximal number of iterations using Hyperdrive and classify using linear regression.

**What are the benefits of the parameter sampler you chose?**
RandomParameterSampling, a parameter sampler which supports disrcrete like uniform and continuous like choice hyperameters. Hyperparamerters are randomly selected from the defined search space.

**What are the benefits of the early stopping policy you chose?**
Using the BanditPolicy - an early stopping policy - to terminate badly performing runs. This algorithm can be adusted by the parameters evaluation interval and slack factor. 

Hyperdrive achieved an accuracy of 0.9144 with the best fitted parameters for the regularization strength '--C' of 0.7386 and the maximal number of iterations '--max_iter' of 200.
![hyperdrive](https://github.com/Daniel-car1/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/docs/Hyperdrive.PNG)

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
AutoML is a machine learning technology to train and tune a model using the target metric for a dataset to find the best fitting model. Due to the task, the AutoML configuration provides the classification task and accuracy as primary metric to compare the best AutoML model with the Scikit-learn Pipeline. Several classification algorithms like LogisticRegression, RandomForest etc. were tested. The best fitting classification algorithm VotingEnsemble reached an accuracy of 0.9157 after an duration of 1m25s.
![AutoML](https://github.com/Daniel-car1/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/docs/AutoML_algos.PNG)


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
The accuracy obtained by the Scikit-learn pipeline with Hyperdrive hyperparameter tuning is 0.914. Whereas, the accuracy obtained by the best AutoMl model VotingEnsemble reaches 0.916, both values are quite similar. Deviatins result from the different architectures, the Scikit-learn pipline uses the linear regression classification algorithm, whereas AutoML tests a pool of different classification algorithms.
The AutoML is a useful approach, because it tests different algorithms.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
* Cleaning the data more precise
* For Hyperdrive: improving the parameter sampler
* Update the clean_data function to obtain pandas datasets and tablular dataset

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
![AutoML](https://github.com/Daniel-car1/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/docs/Delete_code.PNG)
![AutoML](https://github.com/Daniel-car1/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/docs/Delete.PNG)
**Image of cluster marked for deletion**
